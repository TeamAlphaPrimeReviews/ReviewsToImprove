{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"sw_good.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>good_or_bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>To help combat the slew of stupidity from naci...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>Ruined my childhood hero, Luke Skywalker's leg...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Loved this. Such a great addition to the tradi...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>Excess plot lines and no learning or growth fr...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>stupid sjw bullshit</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                             Review good_or_bad\n",
       "0     5.0  To help combat the slew of stupidity from naci...        Good\n",
       "1     0.5  Ruined my childhood hero, Luke Skywalker's leg...        Good\n",
       "2     5.0  Loved this. Such a great addition to the tradi...        Good\n",
       "3     1.5  Excess plot lines and no learning or growth fr...        Good\n",
       "4     0.5                                stupid sjw bullshit         Bad"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Prepare the text for analysis.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for item in data['Review']:   \n",
    "    # split into words\n",
    "    tokens = word_tokenize(item)\n",
    "    # convert to lowercase\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # remove punctuation and abberations\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    # words is now a list of the significant words\n",
    "    for word in words:\n",
    "        vocab_list.append(word)\n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['help', 'combat', 'slew', 'stupidity', 'nacissitic', 'sw', 'fans', 'must', 'say', 'movie', 'around', 'brilliant', 'cinematogrophy', 'overflowing', 'beauty', 'directed', 'elegant', 'form', 'edited', 'max', 'cathartic', 'payoff', 'technicalties', 'tlj', 'perfect', 'spoilers', 'story', 'plot', 'great', 'base', 'line', 'allows', 'major', 'storylines', 'character', 'development', 'take', 'place', 'stop', 'complaining', 'fuel', 'logic', 'shouldnt', 'think', 'much', 'taking', 'jedi', 'sith', 'perfect', 'let', 'go', 'past', 'kill', 'rian', 'johnson', 'genius'], ['ruined', 'childhood', 'hero', 'luke', 'skywalker', 'legacy', 'wonder', 'mark', 'hamill', 'fundamentally', 'disagreed', 'everything', 'written', 'character', 'unforgivable'], ['loved', 'great', 'addition', 'traditions', 'fun', 'series', 'laughed', 'cried', 'wanted', 'many', 'toys', 'love', 'new', 'characters', 'appreciated', 'nt', 'take', 'seriously', 'except', 'kylo', 'ren', 'course', 'worlds', 'built', 'gorgeous', 'fantastic'], ['excess', 'plot', 'lines', 'learning', 'growth', 'characters', 'introduced', 'previous', 'film', 'created', 'convoluted', 'mess', 'feels', 'way', 'disney', 'trying', 'hard', 'also', 'star', 'wars', 'thereby', 'neither'], ['stupid', 'sjw', 'bullshit'], 'help', 'combat', 'slew', 'stupidity', 'nacissitic', 'sw', 'fans', 'must', 'say', 'movie', 'around', 'brilliant', 'cinematogrophy', 'overflowing', 'beauty', 'directed', 'elegant', 'form', 'edited', 'max', 'cathartic', 'payoff', 'technicalties', 'tlj', 'perfect', 'spoilers', 'story', 'plot', 'great', 'base', 'line', 'allows', 'major', 'storylines', 'character', 'development', 'take', 'place', 'stop', 'complaining', 'fuel', 'logic', 'shouldnt', 'think', 'much', 'taking', 'jedi', 'sith', 'perfect', 'let', 'go', 'past', 'kill', 'rian', 'johnson', 'genius', 'ruined', 'childhood', 'hero', 'luke', 'skywalker', 'legacy', 'wonder', 'mark', 'hamill', 'fundamentally', 'disagreed', 'everything', 'written', 'character', 'unforgivable', 'loved', 'great', 'addition', 'traditions', 'fun', 'series', 'laughed', 'cried', 'wanted', 'many', 'toys', 'love', 'new', 'characters', 'appreciated', 'nt', 'take', 'seriously', 'except', 'kylo', 'ren', 'course', 'worlds', 'built', 'gorgeous', 'fantastic', 'excess', 'plot', 'lines', 'learning', 'growth', 'characters', 'introduced', 'previous', 'film', 'created', 'convoluted', 'mess', 'feels', 'way', 'disney', 'trying', 'hard', 'also', 'star', 'wars', 'thereby', 'neither', 'stupid', 'sjw', 'bullshit', 'help', 'combat', 'slew', 'stupidity', 'nacissitic', 'sw', 'fans', 'must', 'say', 'movie', 'around', 'brilliant', 'cinematogrophy', 'overflowing', 'beauty', 'directed', 'elegant', 'form', 'edited', 'max', 'cathartic', 'payoff', 'technicalties', 'tlj', 'perfect', 'spoilers', 'story', 'plot', 'great', 'base', 'line', 'allows', 'major', 'storylines', 'character', 'development', 'take', 'place', 'stop', 'complaining', 'fuel', 'logic', 'shouldnt', 'think', 'much', 'taking', 'jedi', 'sith', 'perfect', 'let', 'go', 'past', 'kill', 'rian', 'johnson', 'genius', 'ruined', 'childhood', 'hero', 'luke', 'skywalker', 'legacy', 'wonder', 'mark', 'hamill', 'fundamentally', 'disagreed', 'everything', 'written', 'character', 'unforgivable', 'loved', 'great', 'addition', 'traditions', 'fun', 'series', 'laughed', 'cried', 'wanted', 'many', 'toys', 'love', 'new', 'characters', 'appreciated', 'nt', 'take', 'seriously', 'except', 'kylo', 'ren', 'course', 'worlds', 'built', 'gorgeous', 'fantastic', 'excess', 'plot', 'lines', 'learning', 'growth', 'characters', 'introduced', 'previous', 'film', 'created', 'convoluted', 'mess', 'feels', 'way', 'disney', 'trying', 'hard', 'also', 'star', 'wars', 'thereby', 'neither', 'stupid', 'sjw', 'bullshit', 'help', 'combat', 'slew', 'stupidity', 'nacissitic', 'sw', 'fans', 'must', 'say', 'movie', 'around', 'brilliant', 'cinematogrophy', 'overflowing', 'beauty', 'directed', 'elegant', 'form', 'edited', 'max', 'cathartic', 'payoff', 'technicalties', 'tlj', 'perfect', 'spoilers', 'story', 'plot', 'great', 'base', 'line', 'allows', 'major', 'storylines', 'character', 'development', 'take', 'place', 'stop', 'complaining', 'fuel', 'logic', 'shouldnt', 'think', 'much', 'taking', 'jedi', 'sith', 'perfect', 'let', 'go', 'past', 'kill', 'rian', 'johnson', 'genius', 'ruined', 'childhood', 'hero', 'luke', 'skywalker', 'legacy', 'wonder', 'mark', 'hamill', 'fundamentally', 'disagreed', 'everything', 'written', 'character', 'unforgivable', 'loved', 'great', 'addition', 'traditions', 'fun', 'series', 'laughed', 'cried', 'wanted', 'many', 'toys', 'love', 'new', 'characters', 'appreciated', 'nt', 'take', 'seriously', 'except', 'kylo', 'ren', 'course', 'worlds', 'built', 'gorgeous', 'fantastic', 'excess', 'plot', 'lines', 'learning', 'growth', 'characters', 'introduced', 'previous', 'film', 'created', 'convoluted', 'mess', 'feels', 'way', 'disney', 'trying', 'hard', 'also', 'star', 'wars', 'thereby', 'neither', 'stupid', 'sjw', 'bullshit']\n"
     ]
    }
   ],
   "source": [
    "print(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['help',\n",
       " 'combat',\n",
       " 'slew',\n",
       " 'stupidity',\n",
       " 'nacissitic',\n",
       " 'sw',\n",
       " 'fans',\n",
       " 'must',\n",
       " 'say',\n",
       " 'movie',\n",
       " 'around',\n",
       " 'brilliant',\n",
       " 'cinematogrophy',\n",
       " 'overflowing',\n",
       " 'beauty',\n",
       " 'directed',\n",
       " 'elegant',\n",
       " 'form',\n",
       " 'edited',\n",
       " 'max',\n",
       " 'cathartic',\n",
       " 'payoff',\n",
       " 'technicalties',\n",
       " 'tlj',\n",
       " 'perfect',\n",
       " 'spoilers',\n",
       " 'story',\n",
       " 'plot',\n",
       " 'great',\n",
       " 'base',\n",
       " 'line',\n",
       " 'allows',\n",
       " 'major',\n",
       " 'storylines',\n",
       " 'character',\n",
       " 'development',\n",
       " 'take',\n",
       " 'place',\n",
       " 'stop',\n",
       " 'complaining',\n",
       " 'fuel',\n",
       " 'logic',\n",
       " 'shouldnt',\n",
       " 'think',\n",
       " 'much',\n",
       " 'taking',\n",
       " 'jedi',\n",
       " 'sith',\n",
       " 'perfect',\n",
       " 'let',\n",
       " 'go',\n",
       " 'past',\n",
       " 'kill',\n",
       " 'rian',\n",
       " 'johnson',\n",
       " 'genius']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(vocab_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'help': 20, 'combat': 8, 'slew': 43, 'stupidity': 48, 'nacissitic': 32, 'sw': 49, 'fans': 14, 'must': 31, 'say': 40, 'movie': 29, 'around': 1, 'brilliant': 4, 'cinematogrophy': 7, 'overflowing': 33, 'beauty': 3, 'directed': 11, 'elegant': 13, 'form': 15, 'edited': 12, 'max': 28, 'cathartic': 5, 'payoff': 35, 'technicalties': 52, 'tlj': 54, 'perfect': 36, 'spoilers': 44, 'story': 46, 'plot': 38, 'great': 19, 'base': 2, 'line': 25, 'allows': 0, 'major': 27, 'storylines': 47, 'character': 6, 'development': 10, 'take': 50, 'place': 37, 'stop': 45, 'complaining': 9, 'fuel': 16, 'logic': 26, 'shouldnt': 41, 'think': 53, 'much': 30, 'taking': 51, 'jedi': 21, 'sith': 42, 'let': 24, 'go': 18, 'past': 34, 'kill': 23, 'rian': 39, 'johnson': 22, 'genius': 17}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "print(len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.34990409  4.34990409  4.34990409  4.34990409  4.34990409  4.34990409\n",
      "  4.34990409  4.34990409  4.34990409  4.34990409  4.34990409  4.34990409\n",
      "  4.34990409  4.34990409  4.34990409  4.34990409  4.34990409  4.34990409\n",
      "  4.34990409  4.34990409  4.34990409  4.34990409  4.34990409  4.34990409\n",
      "  4.34990409  4.34990409  4.34990409  4.34990409  4.34990409  4.34990409\n",
      "  4.34990409  4.34990409  4.34990409  4.34990409  4.34990409  4.34990409\n",
      "  3.94443898  4.34990409  4.34990409  4.34990409  4.34990409  4.34990409\n",
      "  4.34990409  4.34990409  4.34990409  4.34990409  4.34990409  4.34990409\n",
      "  4.34990409  4.34990409  4.34990409  4.34990409  4.34990409  4.34990409\n",
      "  4.34990409]\n"
     ]
    }
   ],
   "source": [
    "vector = vectorizer.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
