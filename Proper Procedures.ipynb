{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_data = pd.read_csv(\"all_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomizing the rows in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_data = the_data.reindex(np.random.permutation(the_data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good: 96\n",
      "Bad: 85\n"
     ]
    }
   ],
   "source": [
    "# Total instances in the csv data, pre-sorting into train and test.\n",
    "good = 0\n",
    "bad = 0\n",
    "for item in the_data['good/bad']:\n",
    "    if item == 'bad':\n",
    "        bad += 1\n",
    "    if item == 'good':\n",
    "        good += 1\n",
    "print('Good: ' + str(good))\n",
    "print('Bad: ' + str(bad))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for index, row in the_data.iterrows():\n",
    "    sentence = \"\"\n",
    "    # extract the review from the original\n",
    "    review = str(row['review'])\n",
    "    # split into words\n",
    "    tokens = word_tokenize(review)\n",
    "    # convert to lowercase\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # remove punctuation and abberations\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter out stop words & join in a sentence\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    sentence = ' '.join(words)\n",
    "    data.append({'stars': (row['stars']) / 10,\n",
    "                      'review': sentence,\n",
    "                      'good/bad': row['good/bad']})\n",
    "new_frame = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with modified star value & a cleaned up review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting features from text, define target y and data x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_frame['review']\n",
    "Y = new_frame['good/bad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partitioning the data into test and training set\n",
    "split = 0.75\n",
    "split_size = int(len(new_frame)*split)\n",
    "\n",
    "X_train = X[:split_size]\n",
    "X_test = X[split_size:]\n",
    "\n",
    "Y_train = Y[:split_size]\n",
    "Y_test = Y[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf = tfidf_transformer.transform(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good reviews in test data: 24\n",
      "Bad reviews in test data: 22\n"
     ]
    }
   ],
   "source": [
    "#Test data numbers\n",
    "test_good = 0\n",
    "test_bad = 0 \n",
    "\n",
    "for rating in Y_test:\n",
    "    if rating == 'good':\n",
    "        test_good += 1\n",
    "    if rating == 'bad':\n",
    "        test_bad += 1\n",
    "print('Good reviews in test data: ' + str(test_good))\n",
    "print('Bad reviews in test data: ' + str(test_bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97037037037037033"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy on training set\n",
    "clf.score(X_train_tfidf, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.608695652174\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on testing set\n",
    "print(clf.score(X_test_tfidf, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        bad       0.70      0.32      0.44        22\n",
      "       good       0.58      0.88      0.70        24\n",
      "\n",
      "avg / total       0.64      0.61      0.57        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = clf.predict(X_test_tfidf)\n",
    "print(metrics.classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141    loved movie filled enjoyment every second shak...\n",
       "142    visually best star wars film nt like luke port...\n",
       "146    never took critics wrong rian blew opportunity...\n",
       "150    made account write review movie best star wars...\n",
       "156    one point necessary cut umbilical cord best fi...\n",
       "157    film piece shit rian johnson simply destroyed ...\n",
       "158    extremely bad story writing think star wars fa...\n",
       "159    absolute travesty mark hamillthis borderline k...\n",
       "160    silver lining coolest lightsaber battle ever r...\n",
       "162    kicsit még emészteni kell de alapjában jó volt...\n",
       "168    loved saw friday parents mom seen star wars em...\n",
       "169    disney killed star wars poor attempt star wars...\n",
       "172    genuinely bad space gravity would nt arc energ...\n",
       "173    movie ok nothing special made dislike characte...\n",
       "179        emotionally powerful scenes star wars history\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False negative\n",
    "X_test[Y_pred > Y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Messing around to see what we can pull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing it on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['SJW bullshit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test = vect.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bad']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting quality of unsorted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing\n",
    "feature_data = pd.read_csv(\"test2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Reviews: 279\n",
      "Negative Reviews: 411\n"
     ]
    }
   ],
   "source": [
    "# This is to test the data is importing correctly\n",
    "feature_good = 0\n",
    "feature_bad = 0\n",
    "for item in feature_data['stars']:\n",
    "    if item >= 25:\n",
    "        feature_good += 1\n",
    "    else:\n",
    "        feature_bad += 1\n",
    "print('Positive Reviews: ' + str(feature_good))\n",
    "print('Negative Reviews: ' + str(feature_bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "feature_list = []\n",
    "for index, row in feature_data.iterrows():\n",
    "    sentence = \"\"\n",
    "    # extract the review from the original\n",
    "    review = row['review']\n",
    "    # split into words\n",
    "    tokens = word_tokenize(review)\n",
    "    # convert to lowercase\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # remove punctuation and abberations\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter out stop words & join in a sentence\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    sentence = ' '.join(words)\n",
    "    feature_list.append({'stars': (row['stars']) / 10,\n",
    "                      'review': sentence,\n",
    "                      'good/bad': row['good/bad']})\n",
    "feature_frame = pd.DataFrame(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_counts = vect.transform(feature_frame['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<690x2114 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 21742 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_counts = count_vect.transform(feature_frame['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_test = vect.transform(feature_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_pred = clf.predict(feature_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_good = 0\n",
    "feature_bad = 0\n",
    "for i in new_y_pred:\n",
    "    if i == 'good':\n",
    "        feature_good += 1\n",
    "    if i == 'bad':\n",
    "        feature_bad += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad: 108 Good: 582\n"
     ]
    }
   ],
   "source": [
    "print(\"Bad: \" + str(feature_bad) + \" Good: \" + str(feature_good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
